{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Fitbert V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHFIX8qy241l9i7dE5ePXU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onamihoang/DL01/blob/master/Culua.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m51kFOUrKfWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCfSLofcvqfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "!pip install pyfunctional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_mRed00v46Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForMaskedLM, BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "model_name = \"bert-large-uncased\"\n",
        "mask_token = '***mask***'\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level = logging.INFO)\n",
        "\n",
        "bert=BertForMaskedLM.from_pretrained(model_name)\n",
        "tokenizer=BertTokenizer.from_pretrained(model_name)\n",
        "bert.eval()\n",
        "\n",
        "#bertMask = bertMask.to('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96PlfHOsv5A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functional import seq\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Tuple, Union, overload\n",
        "\n",
        "def softmax(x):\n",
        "    return x.exp() / (x.exp().sum(-1)).unsqueeze(-1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkmYNMAQv5Nr",
        "colab_type": "code",
        "outputId": "4555ea14-bf72-4ff6-d044-a34caef757e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "import numpy\n",
        "\n",
        "def get_probs_for_words(sent,w1,w2,w3,w4):\n",
        "    pre , target  ,post = sent.split('***')\n",
        "    if 'mask' in target.lower():\n",
        "        target = ['[MASK]']\n",
        "    else:\n",
        "        target = tokenizer.tokenize(target)\n",
        "        \n",
        "    tokens = ['[CLS]'] + tokenizer.tokenize(pre)\n",
        "    target_idx = len(tokens)\n",
        "    print(target_idx)\n",
        "    tokens+=target+tokenizer.tokenize(post)+['[SEP]']\n",
        "    print(tokens)\n",
        "\n",
        "    input_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "    try:\n",
        "        #word_token = tokenizer.tokenize([w1,w2,w3,w4])\n",
        "        #print(word_token)\n",
        "        word_ids = tokenizer.convert_tokens_to_ids([w1,w2,w3,w4])\n",
        "        print(word_ids)\n",
        "    except KeyError:\n",
        "        print(\"skipping\",w1,w2,\"bad wins\")\n",
        "        return None\n",
        "    tens = torch.LongTensor(input_ids).unsqueeze(0)\n",
        "    print(tens)\n",
        "    res=bert(tens)#[0,target_idx]\n",
        "    preds = res[0]\n",
        "    preds = softmax(preds)\n",
        "    print(type(preds))\n",
        "    print(preds.shape)\n",
        "    #print(preds[0,)\n",
        "    pred = preds[0, target_idx,word_ids]\n",
        "    print(type(pred))\n",
        "    print(pred.shape)\n",
        "    #pred = list(preds)\n",
        "    #probs = softmax(preds)\n",
        "    #print(probs)\n",
        "\n",
        "    \n",
        "    print([float(x) for x in pred])\n",
        "\n",
        "\n",
        "    #predicted_inds = torch.argsort(-predictions[0, masked_index])\n",
        "    \n",
        "\n",
        "masked_string = \" Graduates from the Melrose College of Technology often make ***mask*** contributions in several fields, including engineering, computer sciences and astronomy. \"\n",
        "options = [\"value\", \"valuable\", \"valuably\", \"valuing\"]\n",
        "\n",
        "masked_string = \"Our apartment building's occupancy increased ***mask*** the efforts of our knowledgeable and friendly rental agent, Ms. Gova.\"\n",
        "#'despite', 'due to', 'provided that', 'because'] due to despite\n",
        "\n",
        "\n",
        "a = get_probs_for_words(masked_string, 'despite', 'due to','provided that','because')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "['[CLS]', 'our', 'apartment', 'building', \"'\", 's', 'o', '##cc', '##up', '##ancy', 'increased', '[MASK]', 'the', 'efforts', 'of', 'our', 'knowledge', '##able', 'and', 'friendly', 'rental', 'agent', ',', 'ms', '.', 'gov', '##a', '.', '[SEP]']\n",
            "[2750, 100, 100, 2138]\n",
            "tensor([[  101,  2256,  4545,  2311,  1005,  1055,  1051,  9468,  6279, 11656,\n",
            "          3445,   103,  1996,  4073,  1997,  2256,  3716,  3085,  1998,  5379,\n",
            "         12635,  4005,  1010,  5796,  1012, 18079,  2050,  1012,   102]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 29, 30522])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([4])\n",
            "[0.03151131793856621, 6.148987097276404e-08, 6.148987097276404e-08, 2.9065360649838112e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1oajuelv5Ff",
        "colab_type": "code",
        "outputId": "a3df67b2-4b76-4546-dbd2-da44949706f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "masked_string = \"A firm will not ***mask*** if its employees are unhappy.\"\n",
        "options = ['prosper', 'prosperous', 'prosperity', 'prospering'] #prosper prosperous\n",
        "\n",
        "a = get_probs_for_words(masked_string, \"prosper\", \"prosperous\",\"prosperity\",\"prospering\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "['[CLS]', 'a', 'firm', 'will', 'not', '[MASK]', 'if', 'its', 'employees', 'are', 'unhappy', '.', '[SEP]']\n",
            "[100, 18241, 14165, 100]\n",
            "tensor([[  101,  1037,  3813,  2097,  2025,   103,  2065,  2049,  5126,  2024,\n",
            "         12511,  1012,   102]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 13, 30522])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([4])\n",
            "[7.73514386764873e-07, 2.8502333861979423e-06, 1.3334482673599268e-06, 7.73514386764873e-07]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPrBj3WOwjsJ",
        "colab_type": "code",
        "outputId": "b83ff052-5131-4526-9906-96fff6198220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "\n",
        "#['final', 'finalize', 'finally', 'finality'] finalize final\n",
        "\n",
        "masked_string = \"Ms. Najar wants to ***mask*** the costs by tonight.\"\n",
        "a = get_probs_for_words(masked_string, \"final\", \"finalize\",\"finally\",\"finality\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "['[CLS]', 'ms', '.', 'na', '##jar', 'wants', 'to', '[MASK]', 'the', 'costs', 'by', 'tonight', '.', '[SEP]']\n",
            "[2345, 100, 2633, 100]\n",
            "tensor([[  101,  5796,  1012,  6583, 16084,  4122,  2000,   103,  1996,  5366,\n",
            "          2011,  3892,  1012,   102]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 14, 30522])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([4])\n",
            "[2.929694346676115e-05, 3.1597605811839458e-06, 1.1550563385753776e-06, 3.1597605811839458e-06]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgdUmKlyv4-e",
        "colab_type": "code",
        "outputId": "81405be8-7205-49fe-d225-607e1ac38c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "masked_string = \"The Calgary Inn attaches importance to the ***mask*** of its rooms and always offers good service at reasonable prices.\"\n",
        "#['clean', 'cleanliness', 'cleanly', 'cleanest'] cleanliness clean\n",
        "\"cleaned\": \"clean\",\n",
        "\"cleaner\": \"clean\",\n",
        "\"cleaners\": \"cleaner\",\n",
        "\"cleanest\": \"clean\",\n",
        "\"cleaning\": \"clean\",\n",
        "\"cleanings\": \"cleaning\",\n",
        "\"cleanlier\": \"cleanly\",\n",
        "a = get_probs_for_words(masked_string, \"cleanliness\", \"cleanly\",\"cleanest\",\"clean\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "['[CLS]', 'the', 'calgary', 'inn', 'attache', '##s', 'importance', 'to', 'the', '[MASK]', 'of', 'its', 'rooms', 'and', 'always', 'offers', 'good', 'service', 'at', 'reasonable', 'prices', '.', '[SEP]']\n",
            "[100, 100, 100, 4550]\n",
            "tensor([[  101,  1996, 10112,  7601, 29489,  2015,  5197,  2000,  1996,   103,\n",
            "          1997,  2049,  4734,  1998,  2467,  4107,  2204,  2326,  2012,  9608,\n",
            "          7597,  1012,   102]])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 23, 30522])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([4])\n",
            "[8.846667043371781e-08, 8.846667043371781e-08, 8.846667043371781e-08, 3.41269769705832e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}